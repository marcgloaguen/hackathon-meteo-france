{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import time\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:12.773590Z",
     "start_time": "2024-04-08T15:01:12.334985Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:12.839364Z",
     "start_time": "2024-04-08T15:01:12.782743Z"
    }
   },
   "cell_type": "code",
   "source": "gpt_turbo = ChatOpenAI(model_name=\"gpt-3.5-turbo\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:12.963597Z",
     "start_time": "2024-04-08T15:01:12.961136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"data/Vigilance Table.csv\"\n",
    "loader = CSVLoader(file_path=path)\n",
    "data = loader.load()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:13.268732Z",
     "start_time": "2024-04-08T15:01:13.266157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(data)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:14.955459Z",
     "start_time": "2024-04-08T15:01:13.572997Z"
    }
   },
   "cell_type": "code",
   "source": "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:14.958697Z",
     "start_time": "2024-04-08T15:01:14.956643Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vectorstore.as_retriever()",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:14.961698Z",
     "start_time": "2024-04-08T15:01:14.959379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"contextualize_system_prompt.txt\", \"r\") as files:\n",
    "    contextualize_system_prompt = files.read()\n",
    "\n",
    "with open(\"instruct.txt\", \"r\") as files:\n",
    "    instruct = files.read()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "contextualize_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_prompt.pretty_print()\n",
    "contextualize_chain = contextualize_prompt | gpt_turbo | StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:15.577461Z",
     "start_time": "2024-04-08T15:01:15.574759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question just reformulate it if needed and otherwise return it as is.\n",
      "\n",
      "\n",
      "=============================\u001B[1m Messages Placeholder \u001B[0m=============================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{chat_history}\u001B[0m\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{question}\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", instruct),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "prompt.pretty_print()\n",
    "\n",
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=contextualized_question | retriever\n",
    "    )\n",
    "    | prompt\n",
    "    | gpt_turbo\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:25.261497Z",
     "start_time": "2024-04-08T15:01:25.257927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "Tu es un chatbot spécialiser sur les conseils liés aux intempéries qui ne répond UNIQUEMENT qu'en FRANÇAIS, tu peux t'aider du context suivant pour répondre : \u001B[33;1m\u001B[1;3m{context}\u001B[0m\n",
      "\n",
      "\n",
      "=============================\u001B[1m Messages Placeholder \u001B[0m=============================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{chat_history}\u001B[0m\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{question}\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:31.221163Z",
     "start_time": "2024-04-08T15:01:25.798205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_history = []\n",
    "question = \"Comment se protéger de la canicule en vigilance orange ?\"\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(ai_msg.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour se protéger de la canicule en vigilance orange, voici quelques conseils :\n",
      "\n",
      "1. Limitez vos sorties, surtout le soir, la nuit et en début de matinée.\n",
      "2. Habillez-vous chaudement en superposant plusieurs couches de vêtements. Portez une couche extérieure imperméable au vent et à l'eau, couvrez-vous la tête et les mains, et évitez de garder des vêtements humides.\n",
      "3. Après être rentré à l'intérieur, assurez-vous de vous reposer suffisamment, prenez une douche ou un bain chaud, alimentez-vous convenablement et buvez des boissons chaudes (évitez l'alcool).\n",
      "4. Faites attention aux moyens de chauffage utilisés. Les chauffages d'appoint ne doivent pas fonctionner en continu, et ne jamais utilisez des cuisinières, braséros, etc. pour vous chauffer. Ne bloquez pas les entrées d'air de votre logement.\n",
      "5. Aérez votre logement quelques minutes même en hiver.\n",
      "6. Évitez les efforts brusques.\n",
      "\n",
      "N'hésitez pas à consulter les sites officiels pour plus d'informations :\n",
      "- https://sante.gouv.fr/\n",
      "- https://www.santepubliquefrance.fr/\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:35.607996Z",
     "start_time": "2024-04-08T15:01:31.222351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_history = []\n",
    "question = \"Que dois-je faire dans une zone inondable\"\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(ai_msg.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si vous vous trouvez dans une zone inondable, voici quelques conseils à suivre :\n",
      "\n",
      "- Restez chez vous et tenez-vous informé auprès des autorités.\n",
      "- Éloignez-vous des cours d'eau, des points bas et des ponts, et rejoignez le point le plus haut possible.\n",
      "- Évitez d'utiliser votre voiture.\n",
      "- Ne cherchez pas à récupérer vos enfants à l'école.\n",
      "- Réfugiez-vous en étage, et en dernier recours sur le toit, sans descendre dans les sous-sols.\n",
      "- Évacuez uniquement sur ordre des autorités en emportant votre kit d'urgence.\n",
      "\n",
      "Ces mesures de précaution peuvent vous aider à rester en sécurité en cas d'inondation.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:01:41.562546Z",
     "start_time": "2024-04-08T15:01:35.608716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_history = [HumanMessage(content=question), ai_msg]\n",
    "question = (\"comment me tenir informé de l'évolution\")\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(ai_msg.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour vous tenir informé de l'évolution de la situation en cas d'intempéries, voici quelques recommandations :\n",
      "\n",
      "- Suivez les informations diffusées par les autorités compétentes, telles que la préfecture, la mairie ou les services météorologiques.\n",
      "- Consultez régulièrement les bulletins météorologiques et les alertes de vigilance.\n",
      "- Restez à l'écoute des médias locaux (radio, télévision) pour des mises à jour en temps réel.\n",
      "- Utilisez les applications mobiles dédiées aux alertes météorologiques pour recevoir des notifications.\n",
      "- Restez en contact avec vos proches pour vous tenir mutuellement informés de la situation.\n",
      "\n",
      "En restant attentif aux informations officielles et en suivant les consignes de sécurité, vous pourrez mieux gérer les intempéries et protéger votre sécurité.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
